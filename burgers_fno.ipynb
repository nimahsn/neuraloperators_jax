{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import equinox as eqx\n",
    "from models.fno import FNO1d\n",
    "from data.utils import MatDataset, load_mat_data, jax_collate\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurgersDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, input_steps: int, future_steps: int, key: jax.random.PRNGKey):\n",
    "        self.data = load_mat_data(path)\n",
    "        self.tspan = self.data['tspan']\n",
    "        self.data['output'][:, 0, :] = self.data['input']\n",
    "        self.data = self.data['output']\n",
    "        self.key = key\n",
    "        self.input_steps = input_steps\n",
    "        self.future_steps = future_steps\n",
    "        self.x = np.linspace(0, 1, 1024, endpoint=True).reshape(1, -1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] * (self.data.shape[1] - self.future_steps - self.input_steps)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i = idx // (self.data.shape[1] - self.future_steps - self.input_steps)\n",
    "        j = idx % (self.data.shape[1] - self.future_steps - self.input_steps)\n",
    "        return np.concatenate([self.data[i, j:j+self.input_steps], self.x], axis=0), self.data[i, j+self.input_steps:j+self.input_steps+self.future_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimahsn/.conda/envs/jax/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:227: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n"
     ]
    }
   ],
   "source": [
    "dataset = BurgersDataset('datasets/burgers_v100_t100_r1024_N2048.mat', 5, 5, jax.random.PRNGKey(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=64, collate_fn=jax_collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(eqx.filter_vmap, in_axes=(None, 0, 0))\n",
    "def loss_fn(model, data, label):\n",
    "    out = model(data)\n",
    "    return optax.l2_loss(out, label)\n",
    "\n",
    "def train(model: 'eqx.Module', dataloader: 'DataLoader', optimizer: optax.GradientTransformation, n_epochs, opt_state=None, history: dict=None, print_every_steps=2000):\n",
    "    if opt_state is None:\n",
    "        opt_state = optimizer.init(eqx.filter(model, eqx.is_array))\n",
    "    if history is None:\n",
    "        history = {'loss': []}\n",
    "\n",
    "    loss_f = eqx.filter_value_and_grad(lambda model, data, labels: jnp.mean(loss_fn(model, data, labels)), )\n",
    "        \n",
    "    @eqx.filter_jit\n",
    "    def train_step(model, data, labels, opt_state):\n",
    "        loss, grads = loss_f(model, data, labels)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            data, labels = batch\n",
    "            model, opt_state, loss = train_step(model, data, labels, opt_state)\n",
    "            history['loss'].append(loss)\n",
    "            if step % print_every_steps == 0:\n",
    "                print(f'Epoch {epoch}, Step {step}, Loss {loss}')\n",
    "                \n",
    "    return model, opt_state, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO1d(6, 5, 64, 6, 4, jax.nn.gelu, jax.random.PRNGKey(10))\n",
    "lr_scheduler = optax.schedules.exponential_decay(1e-3, 500, 0.9)\n",
    "optimizer = optax.adam(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0, Loss 0.021976759657263756\n",
      "Epoch 0, Step 2000, Loss 0.00011546241876203567\n",
      "Epoch 1, Step 0, Loss 4.141132376389578e-05\n",
      "Epoch 1, Step 2000, Loss 1.2299183254071977e-05\n",
      "Epoch 2, Step 0, Loss 1.971153324120678e-05\n",
      "Epoch 2, Step 2000, Loss 4.1831495764199644e-05\n",
      "Epoch 3, Step 0, Loss 5.2846666221739724e-05\n",
      "Epoch 3, Step 2000, Loss 2.122859950759448e-05\n",
      "Epoch 4, Step 0, Loss 1.739593608363066e-05\n",
      "Epoch 4, Step 2000, Loss 1.4753706636838615e-05\n",
      "Epoch 5, Step 0, Loss 2.024178502324503e-05\n",
      "Epoch 5, Step 2000, Loss 9.969068742066156e-06\n",
      "Epoch 6, Step 0, Loss 1.3603561455965973e-05\n",
      "Epoch 6, Step 2000, Loss 1.1475144674477633e-05\n",
      "Epoch 7, Step 0, Loss 1.3502404726750683e-05\n",
      "Epoch 7, Step 2000, Loss 1.515400072094053e-05\n",
      "Epoch 8, Step 0, Loss 1.8986858776770532e-05\n",
      "Epoch 8, Step 2000, Loss 1.0824790479091462e-05\n",
      "Epoch 9, Step 0, Loss 1.0140410267922562e-05\n",
      "Epoch 9, Step 2000, Loss 7.931656000437215e-06\n"
     ]
    }
   ],
   "source": [
    "model, opt_state, history = train(model, loader, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
